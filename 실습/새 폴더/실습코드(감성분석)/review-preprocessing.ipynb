{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1f53dcee1f8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOkt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "train_file = DATA_IN_PATH + 'ratings_train.txt'\n",
    "train_data = pd.read_csv(train_file, header=0, delimiter='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아 더빙.. 진짜 짜증나네요 목소리\n",
      "아 더빙 진짜 짜증나네요 목소리\n"
     ]
    }
   ],
   "source": [
    "# 정규표현(re)을 사용해 아래에 해당하지 않는 기호는 모두 제거\n",
    "# 한글음절 :음절 11,174자 ('가'-'힣'), 자음('ㄱ'-'ㅎ'), 모음('ㅏ'-'ㅣ'), whitespace char(\\s)\n",
    "print(train_data['document'][0])\n",
    "review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', '', train_data['document'][0])\n",
    "print(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아 더빙 진짜 짜증나네요 목소리\n",
      "['아', '더빙', '진짜', '짜증나다', '목소리']\n"
     ]
    }
   ],
   "source": [
    "print(review_text)\n",
    "okt = Okt()\n",
    "review_text = okt.morphs(review_text, stem=True)\n",
    "print(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아', '휴', '아이구', '아이쿠', '아이고', '어', '나', '우리', '저희', '따라']\n"
     ]
    }
   ],
   "source": [
    "with open('./kr_stopwords.txt', encoding='utf8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip() for x in stopwords]    \n",
    "print(stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아', '더빙', '진짜', '짜증나다', '목소리']\n",
      "['더빙', '진짜', '짜증나다', '목소리']\n"
     ]
    }
   ],
   "source": [
    "print(review_text)\n",
    "revised_text = [w for w in review_text if len(w) > 1]\n",
    "clean_review = [w for w in revised_text if not w in stopwords]\n",
    "print(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review, remove_stopwords, stop_words):\n",
    "    review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', '', review)\n",
    "    word_review = okt.morphs(review_text, stem=True)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        revised_text = [w for w in word_review if len(w) > 1]\n",
    "        word_review = [token for token in revised_text \n",
    "                       if not token in stop_words]\n",
    "        \n",
    "    return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행률= 0 퍼센트\n",
      "진행률= 1 퍼센트\n",
      "진행률= 2 퍼센트\n",
      "진행률= 3 퍼센트\n",
      "진행률= 4 퍼센트\n",
      "진행률= 5 퍼센트\n",
      "진행률= 6 퍼센트\n",
      "진행률= 7 퍼센트\n",
      "진행률= 8 퍼센트\n",
      "진행률= 9 퍼센트\n",
      "진행률= 10 퍼센트\n",
      "진행률= 11 퍼센트\n",
      "진행률= 12 퍼센트\n",
      "진행률= 13 퍼센트\n",
      "진행률= 14 퍼센트\n",
      "진행률= 15 퍼센트\n",
      "진행률= 16 퍼센트\n",
      "진행률= 17 퍼센트\n",
      "진행률= 18 퍼센트\n",
      "진행률= 19 퍼센트\n",
      "진행률= 20 퍼센트\n",
      "진행률= 21 퍼센트\n",
      "진행률= 22 퍼센트\n",
      "진행률= 23 퍼센트\n",
      "진행률= 24 퍼센트\n",
      "진행률= 25 퍼센트\n",
      "진행률= 26 퍼센트\n",
      "진행률= 27 퍼센트\n",
      "진행률= 28 퍼센트\n",
      "진행률= 28 퍼센트\n",
      "진행률= 30 퍼센트\n",
      "진행률= 31 퍼센트\n",
      "진행률= 32 퍼센트\n",
      "진행률= 33 퍼센트\n",
      "진행률= 34 퍼센트\n",
      "진행률= 35 퍼센트\n",
      "진행률= 36 퍼센트\n",
      "진행률= 37 퍼센트\n",
      "진행률= 38 퍼센트\n",
      "진행률= 39 퍼센트\n",
      "진행률= 40 퍼센트\n",
      "진행률= 41 퍼센트\n",
      "진행률= 42 퍼센트\n",
      "진행률= 43 퍼센트\n",
      "진행률= 44 퍼센트\n",
      "진행률= 45 퍼센트\n",
      "진행률= 46 퍼센트\n",
      "진행률= 47 퍼센트\n",
      "진행률= 48 퍼센트\n",
      "진행률= 49 퍼센트\n",
      "진행률= 50 퍼센트\n",
      "진행률= 51 퍼센트\n",
      "진행률= 52 퍼센트\n",
      "진행률= 53 퍼센트\n",
      "진행률= 54 퍼센트\n",
      "진행률= 55 퍼센트\n",
      "진행률= 56 퍼센트\n",
      "진행률= 56 퍼센트\n",
      "진행률= 57 퍼센트\n",
      "진행률= 59 퍼센트\n",
      "진행률= 60 퍼센트\n",
      "진행률= 61 퍼센트\n",
      "진행률= 62 퍼센트\n",
      "진행률= 63 퍼센트\n",
      "진행률= 64 퍼센트\n",
      "진행률= 65 퍼센트\n",
      "진행률= 66 퍼센트\n",
      "진행률= 67 퍼센트\n",
      "진행률= 68 퍼센트\n",
      "진행률= 69 퍼센트\n",
      "진행률= 70 퍼센트\n",
      "진행률= 71 퍼센트\n",
      "진행률= 72 퍼센트\n",
      "진행률= 73 퍼센트\n",
      "진행률= 74 퍼센트\n",
      "진행률= 75 퍼센트\n",
      "진행률= 76 퍼센트\n",
      "진행률= 77 퍼센트\n",
      "진행률= 78 퍼센트\n",
      "진행률= 79 퍼센트\n",
      "진행률= 80 퍼센트\n",
      "진행률= 81 퍼센트\n",
      "진행률= 82 퍼센트\n",
      "진행률= 83 퍼센트\n",
      "진행률= 84 퍼센트\n",
      "진행률= 85 퍼센트\n",
      "진행률= 86 퍼센트\n",
      "진행률= 87 퍼센트\n",
      "진행률= 88 퍼센트\n",
      "진행률= 89 퍼센트\n",
      "진행률= 90 퍼센트\n",
      "진행률= 91 퍼센트\n",
      "진행률= 92 퍼센트\n",
      "진행률= 93 퍼센트\n",
      "진행률= 94 퍼센트\n",
      "진행률= 95 퍼센트\n",
      "진행률= 96 퍼센트\n",
      "진행률= 97 퍼센트\n",
      "진행률= 98 퍼센트\n",
      "진행률= 99 퍼센트\n"
     ]
    }
   ],
   "source": [
    "clean_train_review = []\n",
    "\n",
    "i = 0\n",
    "max = len(train_data['document'])\n",
    "for review in train_data['document']:\n",
    "    if (i % 1500 == 0):\n",
    "        print('진행률= %d 퍼센트' % ((i/max * 100)+1))\n",
    "    if type(review) == str:\n",
    "        clean_train_review.append(preprocessing(review, True, stopwords))\n",
    "    else:\n",
    "        clean_train_review.append([])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['더빙', '진짜', '짜증나다', '목소리'],\n",
       " ['포스터', '보고', '초딩', '영화', '오버', '연기', '가볍다', '않다'],\n",
       " ['무재', '밓었', '다그', '래서', '보다', '추천'],\n",
       " ['교도소', '이야기', '구먼', '솔직하다', '재미', '없다', '평점', '조정'],\n",
       " ['사이',\n",
       "  '몬페',\n",
       "  '익살스럽다',\n",
       "  '연기',\n",
       "  '돋보이다',\n",
       "  '영화',\n",
       "  '스파이더맨',\n",
       "  '늙다',\n",
       "  '보이다',\n",
       "  '하다',\n",
       "  '커스틴',\n",
       "  '던스트',\n",
       "  '너무나도',\n",
       "  '이쁘다',\n",
       "  '보이다']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_review[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(clean_train_review)\n",
    "len(train_data['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행률= 1 퍼센트\n",
      "진행률= 2 퍼센트\n",
      "진행률= 3 퍼센트\n",
      "진행률= 4 퍼센트\n",
      "진행률= 5 퍼센트\n",
      "진행률= 6 퍼센트\n",
      "진행률= 7 퍼센트\n",
      "진행률= 8 퍼센트\n",
      "진행률= 9 퍼센트\n",
      "진행률= 10 퍼센트\n",
      "진행률= 11 퍼센트\n",
      "진행률= 12 퍼센트\n",
      "진행률= 13 퍼센트\n",
      "진행률= 14 퍼센트\n",
      "진행률= 15 퍼센트\n",
      "진행률= 16 퍼센트\n",
      "진행률= 17 퍼센트\n",
      "진행률= 18 퍼센트\n",
      "진행률= 19 퍼센트\n",
      "진행률= 20 퍼센트\n",
      "진행률= 21 퍼센트\n",
      "진행률= 22 퍼센트\n",
      "진행률= 23 퍼센트\n",
      "진행률= 24 퍼센트\n",
      "진행률= 25 퍼센트\n",
      "진행률= 26 퍼센트\n",
      "진행률= 27 퍼센트\n",
      "진행률= 28 퍼센트\n",
      "진행률= 29 퍼센트\n",
      "진행률= 29 퍼센트\n",
      "진행률= 31 퍼센트\n",
      "진행률= 32 퍼센트\n",
      "진행률= 33 퍼센트\n",
      "진행률= 34 퍼센트\n",
      "진행률= 35 퍼센트\n",
      "진행률= 36 퍼센트\n",
      "진행률= 37 퍼센트\n",
      "진행률= 38 퍼센트\n",
      "진행률= 39 퍼센트\n",
      "진행률= 40 퍼센트\n",
      "진행률= 41 퍼센트\n",
      "진행률= 42 퍼센트\n",
      "진행률= 43 퍼센트\n",
      "진행률= 44 퍼센트\n",
      "진행률= 45 퍼센트\n",
      "진행률= 46 퍼센트\n",
      "진행률= 47 퍼센트\n",
      "진행률= 48 퍼센트\n",
      "진행률= 49 퍼센트\n",
      "진행률= 50 퍼센트\n",
      "진행률= 51 퍼센트\n",
      "진행률= 52 퍼센트\n",
      "진행률= 53 퍼센트\n",
      "진행률= 54 퍼센트\n",
      "진행률= 55 퍼센트\n",
      "진행률= 56 퍼센트\n",
      "진행률= 57 퍼센트\n",
      "진행률= 57 퍼센트\n",
      "진행률= 58 퍼센트\n",
      "진행률= 60 퍼센트\n",
      "진행률= 61 퍼센트\n",
      "진행률= 62 퍼센트\n",
      "진행률= 63 퍼센트\n",
      "진행률= 64 퍼센트\n",
      "진행률= 65 퍼센트\n",
      "진행률= 66 퍼센트\n",
      "진행률= 67 퍼센트\n",
      "진행률= 68 퍼센트\n",
      "진행률= 69 퍼센트\n",
      "진행률= 70 퍼센트\n",
      "진행률= 71 퍼센트\n",
      "진행률= 72 퍼센트\n",
      "진행률= 73 퍼센트\n",
      "진행률= 74 퍼센트\n",
      "진행률= 75 퍼센트\n",
      "진행률= 76 퍼센트\n",
      "진행률= 77 퍼센트\n",
      "진행률= 78 퍼센트\n",
      "진행률= 79 퍼센트\n",
      "진행률= 80 퍼센트\n",
      "진행률= 81 퍼센트\n",
      "진행률= 82 퍼센트\n",
      "진행률= 83 퍼센트\n",
      "진행률= 84 퍼센트\n",
      "진행률= 85 퍼센트\n",
      "진행률= 86 퍼센트\n",
      "진행률= 87 퍼센트\n",
      "진행률= 88 퍼센트\n",
      "진행률= 89 퍼센트\n",
      "진행률= 90 퍼센트\n",
      "진행률= 91 퍼센트\n",
      "진행률= 92 퍼센트\n",
      "진행률= 93 퍼센트\n",
      "진행률= 94 퍼센트\n",
      "진행률= 95 퍼센트\n",
      "진행률= 96 퍼센트\n",
      "진행률= 97 퍼센트\n",
      "진행률= 98 퍼센트\n",
      "진행률= 99 퍼센트\n",
      "진행률= 100 퍼센트\n"
     ]
    }
   ],
   "source": [
    "test_file = DATA_IN_PATH + 'ratings_test.txt'\n",
    "test_data = pd.read_csv(test_file, header=0, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "clean_test_review = []\n",
    "\n",
    "i = 0\n",
    "max = len(test_data['document'])\n",
    "for review in test_data['document']:\n",
    "    if i % 500 == 0:\n",
    "        print('진행률= %d 퍼센트' % ((i/max * 100)+1))\n",
    "        \n",
    "    if type(review) == str:\n",
    "        clean_test_review.append(preprocessing(review,True, stopwords))\n",
    "    else:\n",
    "        clean_test_review.append([])\n",
    "    i += 1                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_test_review)\n",
    "#len(clean_test_review[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow를 사용해 기계학습모델에 적용하기 위해서는 단어를 그대로 사용할 수 없으며,\n",
    "텍스트 데이터인 단어를 수치 데이터로 변환해야 함.\n",
    "따라서, text_to_sequences 라이브러리를 사용하여 전처리가 끝난 \n",
    "train_review와 test_review의 각 벡터를 index로 구성된 벡터로 변환.\n",
    "모든 index는 word_vocab에 저장되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_review)\n",
    "train_sequence = tokenizer.texts_to_sequences(clean_train_review)\n",
    "test_sequence = tokenizer.texts_to_sequences(clean_test_review)\n",
    "\n",
    "word_vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['더빙', '진짜', '짜증나다', '목소리']\n",
      "[314, 11, 165, 460]\n",
      "41927\n"
     ]
    }
   ],
   "source": [
    "print(clean_train_review[0])\n",
    "print(train_sequence[0])\n",
    "#print(word_vocab)\n",
    "print(len(word_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 벡터는 서로 길이가 다름. 이 길이를 하나로 통일해야 기계학습모델에 적용할 수 있음.\n",
    "최대 길이(MAX_SEQUENCE_LENGTH=8)를 정하고, 이 길이보다 긴 벡터는 자르며,\n",
    "이 길이보다 짧은 벡터는 빈 자리에 0을 추가(padding)한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUNCE_LENGTH = 8\n",
    "\n",
    "train_inputs = pad_sequences(train_sequence, maxlen=MAX_SEQUNCE_LENGTH, padding='post')\n",
    "train_labels = np.array(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  314    11   165   460     0     0     0     0]\n",
      " [  315    24   415     1  1099    16   472    13]\n",
      " [ 1934 23578  1816  4906     2   137     0     0]\n",
      " [ 5691    66  7229   135    32     4    17  2988]\n",
      " [  807   149     3 13120 18142   781   160   149]]\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = pad_sequences(test_sequence, maxlen=MAX_SEQUNCE_LENGTH, padding='post')\n",
    "test_labels = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "TRAIN_INPUT_DATA = 'nsmc_train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'nsmc_train_label.npy'\n",
    "TEST_INPUT_DATA = 'nsmc_test_input.npy'\n",
    "TEST_LABEL_DATA = 'nsmc_test_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_configs = {}\n",
    "\n",
    "data_configs['vocab'] = word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(DATA_IN_PATH):\n",
    "    ok.makedirs(DATA_IN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(DATA_IN_PATH + TRAIN_INPUT_DATA, 'wb'), train_inputs)\n",
    "np.save(open(DATA_IN_PATH + TRAIN_LABEL_DATA, 'wb'), train_labels)\n",
    "np.save(open(DATA_IN_PATH + TEST_INPUT_DATA, 'wb'), test_inputs)\n",
    "np.save(open(DATA_IN_PATH + TEST_LABEL_DATA, 'wb'), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data_configs, open(DATA_IN_PATH + DATA_CONFIGS, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "TEST_CLEAN_DATA = 'test_clean.csv'\n",
    "clean_train_df = pd.DataFrame({'review':clean_train_review, \n",
    "                              'sentiment':train_data['label']})\n",
    "clean_test_df = pd.DataFrame({'review':clean_test_review, \n",
    "                              'sentiment':test_data['label']})\n",
    "clean_train_df.to_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA, index=False)\n",
    "clean_test_df.to_csv(DATA_IN_PATH + TEST_CLEAN_DATA, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
